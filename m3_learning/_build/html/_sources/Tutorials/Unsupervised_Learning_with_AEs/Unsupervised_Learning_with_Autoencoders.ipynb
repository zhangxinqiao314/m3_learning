{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxrwNCW3d_W5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unsupervised Spectral Unmixing with Autoencoders\n",
    "\n",
    "By Joshua C. Agar, Shuyu Qin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxrwNCW3d_W5",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are many times where you want to extract imporant features from high-dimensional data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxrwNCW3d_W5",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In essence, the goal is to compress data to some lower latent space where you can extract information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Du1zN74ev1K",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/3-swissroll-unfolded.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb7JkH3jffXB",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Autoencoder\n",
    "\n",
    "![imag](https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/Autoencoder.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb7JkH3jffXB",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Encoder** - Neural network that deconstructs the data into the most important statistical components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb7JkH3jffXB",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Embedding Layer(s)** - One or many layers were information is extracted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb7JkH3jffXB",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Decoder** - Neural network that translates the latent space to original dimensionality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mathematical Objective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Minimize the reconstruction loss based on some metric.\n",
    "  - Mean squared error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Good at avoiding influence of anomalies\n",
    "  - Mean absolute error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Good at capturing details within spectra\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Optimizers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Standard optimizers like ADAM tend to be sufficient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Can use more complex optimizers 2nd order, adhessian to optimize small models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Practical Objective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Create an autoencoder that has performant reconstruction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Create a low-dimensional and interpretable latent space\n",
    "  - Reduce the dimensionality\n",
    "  - Impose non-negativity contraints\n",
    "  - Impose regularization\n",
    "  - Impose sparsity\n",
    "  - Impose constraints on the shape of the latent distribution\n",
    "  - Impose soft-constraints that favor disentanglement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Create a latent trajectory that is suitable for generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oWjlBBJzs73",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Imports Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# installs the tutorial package\n",
    "!pip install m3_learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0VKiyka604-",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from m3_learning.viz.nn import embeddings, latent_generator\n",
    "from m3_learning.nn.random import random_seed\n",
    "from m3_learning.viz.style import set_style\n",
    "from m3_learning.nn.time_series_nn.nn_util import Train, transform_nn, loss_function\n",
    "from m3_learning.viz.layout import layout_fig, embedding_maps\n",
    "from m3_learning.util.data_generators import generate_data\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torchsummary import summary\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "set_style(\"printing\")\n",
    "random_seed(seed=42)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXjwNNaSz5MS",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generating Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXjwNNaSz5MS",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We want to generate a hyperspectral image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXjwNNaSz5MS",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This can be done by taking the RGB values of an image and using them as parameters for a function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJLKait50MP6",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Loads and image of my dog Nala\n",
    "\n",
    "- Painting by _Irene Dogmatic_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MG4YZi2tfeSi",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Loads dog image\n",
    "image = io.imread(\n",
    "    \"https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/nala.jpg?raw=true\"\n",
    ")\n",
    "\n",
    "# Crops dog image\n",
    "image = image[200:1900:20, 100:1500:20] / 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUpSmdfP0Ysv",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Displays the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "ud8Peh1Sd9CJ",
    "outputId": "544afbbf-a8b8-4520-a029-ed86d5997c4d",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8x-NFM-D0hpm",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Generating some data based on the image\n",
    "\n",
    "### Define a non-linear function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EmkJWMFZ2lP",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/generated.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDjT0mgu8BbE",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def non_linear_fn(t, x, y, z):\n",
    "    tanh = nn.Tanh()\n",
    "    selu = nn.SELU()\n",
    "    sigmoid = nn.Sigmoid()\n",
    "\n",
    "    # returns a function from variables\n",
    "    return (\n",
    "        tanh(torch.tensor(20 * (t - 2 * (x - 0.5))))\n",
    "        + selu(torch.tensor((t - 2 * (y - 0.5))))\n",
    "        + sigmoid(torch.tensor(-20 * (t - (z - 0.5))))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgyhh4WH048G",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# generates a hyperspectral image\n",
    "dog_data = generate_data(image.reshape(-1, 3),\n",
    "                         length=10, function=non_linear_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDoZk7t178n_",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Conducts a test train split.\n",
    "# because we are training an autoencoder x and y are the same\n",
    "X_train, X_test, _, _ = train_test_split(\n",
    "    dog_data, dog_data, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qh-D-oH615jI",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Plots the generated data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "fgblwFiWf0b0",
    "outputId": "4900b4e7-5c18-4162-d34f-7d80690a59ee",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = layout_fig(6, mod=3, figsize=(5, 2.5))\n",
    "\n",
    "ax = ax.ravel()\n",
    "\n",
    "cmap = plt.cm.viridis\n",
    "\n",
    "for i, ax in enumerate(ax):\n",
    "    if i < 3:\n",
    "        # imagemap(ax, image[:, :, i],divider_=False, clim = (0,1))\n",
    "        img = np.zeros(image.shape)\n",
    "        img[:, :, i] = image[:, :, i]\n",
    "        ax.imshow(img)\n",
    "    else:\n",
    "        values = np.zeros((5, 3))\n",
    "        values[:, i - 3] = np.linspace(0, 1, 5)\n",
    "        y_data = generate_data(values, length=10)\n",
    "        for j in range(y_data.shape[0]):\n",
    "            color = cmap((j + 1) / y_data.shape[0])\n",
    "            ax.plot(y_data[j], c=color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kI_jGvwM9Qz1",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building a Simple Autoencoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QkBuOi98j6K",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Defines the encoder and the decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cMY_3I9mJ0X",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 12\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=12):\n",
    "        self.latent_dim = latent_dim\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dense_1 = nn.Linear(10, self.latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # single dense layer in the model\n",
    "        x = self.dense_1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=12):\n",
    "        self.latent_dim = latent_dim\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dense_1 = nn.Linear(self.latent_dim, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # single dense layer in the decoder\n",
    "        x = self.dense_1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfc1_DKg89Il",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Builds the autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxBAeRAjn3j3",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        embedding = self.encoder(x)\n",
    "        # decode\n",
    "        predicted = self.decoder(embedding)\n",
    "\n",
    "        return predicted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoxAH5zO9E3-",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Instantiates the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cNWSsKsoYSi",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import cpuinfo\n",
    "\n",
    "cpudata = cpuinfo.get_cpu_info()[\"brand_raw\"]\n",
    "cpuname = cpudata.split(\" \")[1]\n",
    "\n",
    "if cpuname == \"M1\":\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.device_count():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"You are running on a {device}\")\n",
    "\n",
    "encoder = Encoder().to(device)\n",
    "decoder = Decoder().to(device)\n",
    "model = Autoencoder(encoder, decoder).to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "km3uI5CH8huM",
    "outputId": "cd6b3080-a2cb-412f-9b4b-ad49dfce17ec",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    summary(model, ((X_train.shape[1:])))\n",
    "except:\n",
    "    model_cpu = copy.deepcopy(model).to(\"cpu\")\n",
    "    summary(model_cpu, ((X_train.shape[1:])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j25InFsO9ltY",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Encoder with 12 latent dimensions\n",
    "- Decoder with with size 10 --> same as orignal spectral length\n",
    "- Autoencoder considers time by saying each timestep is its own fully-uncorrelated sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Builds the dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6o4khQII-uL_",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_iterator = torch.utils.data.DataLoader(\n",
    "    X_train, batch_size=256, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Trains the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3aRHZYt2-05O",
    "outputId": "65b0572b-c4be-45f8-a936-209b7f65ebbd",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_seed(seed=42)\n",
    "Train(model, encoder, decoder, train_iterator, optimizer, 500, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluates the model after training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PkUSAm6bD8gb",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "encode, decode = transform_nn(dog_data, encoder, decoder, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 630
    },
    "id": "x15LcmeSEXtM",
    "outputId": "2e4a5f8f-d1b6-48a6-aee6-03511e18bac9",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "embeddings(encode, shape_=image.shape[0:2], figsize=(5, 3), clim=(-2, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvcvX4PMEpnW",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is clearly an overcomplete example since we are learning 10 timesteps with 12 latent variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDUFWLs6-dkF",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We know that we only have 3 intrinsic latent variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tl8BkctFm6vC",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model with 3 latent variables\n",
    "\n",
    "### Instantiates the model (3 latent variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdCRnufQm6vC",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(latent_dim=3).to(device)\n",
    "decoder = Decoder(latent_dim=3).to(device)\n",
    "model = Autoencoder(encoder, decoder).to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TGBtA4Qdm6vC",
    "outputId": "701ab334-205e-45e1-bb4c-abaf9f21e4ab",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "summary(model, ((X_train.shape[1:])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vijFKSkSm6vD",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Encoder with 3 latent dimensions\n",
    "- Decoder with with size 10 --> same as orignal spectral length\n",
    "- Autoencoder considers time by saying each timestep is its own fully-uncorrelated sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AmyDq0a-m6vD",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_iterator = torch.utils.data.DataLoader(\n",
    "    X_train, batch_size=256, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Trains the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6EwGfIV4m6vD",
    "outputId": "28d4d430-b788-436f-a99e-6020b819cc22",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "random_seed(seed=42)\n",
    "Train(model, encoder, decoder, train_iterator, optimizer, 500, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GUd6n2n4m6vD",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "encode, decode = transform_nn(dog_data, encoder, decoder, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "NMa1SoDym6vD",
    "outputId": "15627cf7-21db-42f5-ffe8-ac4342e274d9",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "embeddings(encode, shape_=image.shape[0:2], figsize=(4.5, 1.25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwA-Tvkmm6vD",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is clearly an overcomplete example since we are learning 10 timesteps with 12 latent variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyxCzFQpR8Qf",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Generator\n",
    "\n",
    "- Now we want to see how the spectra changes as we traverse the latent space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "0N1pohL3pFSX",
    "outputId": "9daeb97b-0c99-4a38-ef24-1c8fde818380",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "latent_generator(decoder, encode, image, 5, 10, device=device,\n",
    "                 figsize=(5, 2.5), divider_=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV0CTdFaqtEY",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Recurrent Neural Network Autoencoders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV0CTdFaqtEY",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The above example did not consider the temporal information in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV0CTdFaqtEY",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This can be improved by using a recurrent neural network that processes each time step sequentially.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV0CTdFaqtEY",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To add an understanding about the short and long term information in the data you can add memory and forget logic as a learnable parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fV0CTdFaqtEY",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/Autoencoder_Med.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhTv9qVIaSKZ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/LSTM%20Node.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Builds the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VpPgTyg5qsBj",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 12\n",
    "\n",
    "# input (batch,)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=12):\n",
    "        self.latent_dim = latent_dim\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(1, 12, batch_first=True, bidirectional=True)\n",
    "        self.embedding = nn.Linear(24, self.latent_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, (_, __) = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.embedding(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=12):\n",
    "        self.latent_dim = latent_dim\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(self.latent_dim, 12,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "        self.tdd = nn.Conv1d(24, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x[:, :, None]\n",
    "        x = x.transpose(1, 2)\n",
    "        x = x.repeat([1, 10, 1])\n",
    "        x, (_, __) = self.lstm(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.tdd(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxQRoBpkmsMG",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "encoder = Encoder().to(device)\n",
    "decoder = Decoder().to(device)\n",
    "model = Autoencoder(encoder, decoder).to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-kgrRjyL6IQe",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_iterator = torch.utils.data.DataLoader(\n",
    "    np.atleast_3d(X_train), batch_size=256, shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pI6_sXa6IQf",
    "outputId": "d414f06f-13cb-4344-947c-d0f872bc638f",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "random_seed(seed=42)\n",
    "Train(model, encoder, decoder, train_iterator, optimizer, 500, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-9ko8uLpARY",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "encode, decode = transform_nn(dog_data, encoder, decoder, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "id": "CpemVGfyDhar",
    "outputId": "3bc0399d-c7bf-4ae8-c584-c663fa8da028",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "embeddings(encode, shape_=image.shape[0:2], figsize=(5, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBIIsSGPGdRg",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This does not really mean too much because the latent variables are all competing with one another\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3n59_TQ3Gn3H",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LSTM Autoencoder with 3 Latent Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxZpZfDaGvtP",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(latent_dim=3).to(device)\n",
    "decoder = Decoder(latent_dim=3).to(device)\n",
    "model = Autoencoder(encoder, decoder).to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aX2Ap7nZGvtP",
    "outputId": "514f051a-e79f-479c-9ac7-4659cb33f6ff",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkRnYS7YGvtP",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_iterator = torch.utils.data.DataLoader(\n",
    "    np.atleast_3d(X_train), batch_size=256, shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yA-7waBrGvtP",
    "outputId": "6b0ba1ed-4775-4a8f-9ea9-f6baf952dd89",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "random_seed(seed=42)\n",
    "\n",
    "Train(model, encoder, decoder, train_iterator, optimizer, 500, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xx6HnYjSGvtP",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "encode, decode = transform_nn(dog_data, encoder, decoder, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "5RZYrA-tGvtP",
    "outputId": "48ab1546-c1ac-46d6-8330-f51fd7383ff7",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "embeddings(encode, shape_=image.shape[0:2], figsize=(4.5, 1.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "GJ86cQiXGYzE",
    "outputId": "5442ab98-2781-4902-cc8b-1df7ddc006cf",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "latent_generator(decoder, encode, image, 5, 10, device=device,\n",
    "                 figsize=(5, 2.5), divider_=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_giijefIzF2",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This once again is very hard to interpret and the spectra do not really contain the necessary details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMyxBetpJamg",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Disentanglement\n",
    "\n",
    "### Regularization\n",
    "\n",
    "![](https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/L1_reg.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Builds the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSX_7SdDJaGl",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 12\n",
    "\n",
    "# input (batch,)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=12):\n",
    "        self.latent_dim = latent_dim\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(1, 12, batch_first=True, bidirectional=True)\n",
    "        self.embedding = nn.Linear(24, self.latent_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, (_, __) = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.embedding(x)\n",
    "        x = self.relu(x)  # add a relu\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=12):\n",
    "        self.latent_dim = latent_dim\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(self.latent_dim, 12,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "        self.tdd = nn.Conv1d(24, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x[:, :, None]\n",
    "        x = x.transpose(1, 2)\n",
    "        x = x.repeat([1, 10, 1])\n",
    "        x, (_, __) = self.lstm(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.tdd(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORlK3DY5KBv8",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "encoder = Encoder().to(device)\n",
    "decoder = Decoder().to(device)\n",
    "model = Autoencoder(encoder, decoder).to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGJe2VxWKBv8",
    "outputId": "0e5a3eaa-5dea-442a-faa7-74360f572f6e",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bkm3Tc1KKBv9",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_iterator = torch.utils.data.DataLoader(\n",
    "    np.atleast_3d(X_train), batch_size=256, shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U54m0q8yKBv9",
    "outputId": "096b7983-5347-42be-a03d-61ef4fd66fa2",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "random_seed(seed=42)\n",
    "\n",
    "Train(\n",
    "    model,\n",
    "    encoder,\n",
    "    decoder,\n",
    "    train_iterator,\n",
    "    optimizer,\n",
    "    500,\n",
    "    coef=1e-3,\n",
    "    mse=False,\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vLDkYlnAKBv-",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "encode, decode = transform_nn(dog_data, encoder, decoder, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "7o9IYLppKBv-",
    "outputId": "8b5c8517-6bcf-4cd0-f49e-3835456c1fe4",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "embeddings(encode, shape_=image.shape[0:2], figsize=(4.5, 3.75))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "iCzmhDLhDweA",
    "outputId": "d7f9a9e9-9eb9-4923-ae57-121335b446d8",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "latent_generator(decoder, encode, image, 5, 10, device=device,\n",
    "                 figsize=(5, 2.5), divider_=False, indx=[2, 8, 9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "P37ZL7fbDhNY",
    "outputId": "092e718b-2771-4a8c-e156-2504bcddfd7c",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = layout_fig(6, mod=3)\n",
    "\n",
    "ax = ax.ravel()\n",
    "\n",
    "cmap = plt.cm.viridis\n",
    "\n",
    "for i, ax in enumerate(ax):\n",
    "    if i < 3:\n",
    "        img = np.zeros(image.shape)\n",
    "        img[:, :, i] = image[:, :, i]\n",
    "        ax.imshow(img)\n",
    "    else:\n",
    "        values = np.zeros((5, 3))\n",
    "        values[:, i - 3] = np.linspace(0, 1, 5)\n",
    "        y_data = generate_data(values, length=10)\n",
    "        for j in range(y_data.shape[0]):\n",
    "            color = cmap((j + 1) / y_data.shape[0])\n",
    "            ax.plot(y_data[j], c=color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "GUGPRAALbPTt",
    "outputId": "bac1d97b-6529-4469-9670-0d203dd3232a",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Youtube\n",
    "HTML(\n",
    "    '<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ElTwQClLsW0\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC20v8u0OTQw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Beta Variational Autoencoder\n",
    "\n",
    "- Constrict and sample the latent space from some prior distribution --> generally a gaussian distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC20v8u0OTQw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Normal Autoencoder\n",
    "\n",
    "![](https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/VAE1.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC20v8u0OTQw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### VAE\n",
    "\n",
    "- Encoder identifies some distribution --> generates from that distribution\n",
    "  ![](https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/VAE2.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC20v8u0OTQw",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/VAE3.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC20v8u0OTQw",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://github.com/jagar2/m3_learning/blob/main/m3_learning/Tutorials/Unsupervised_Learning_with_AEs/figs/VAE4.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Builds the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzR5OXxbOSn_",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "latent_dim = 12\n",
    "\n",
    "# input (batch,)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=12):\n",
    "        self.latent_dim = latent_dim\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(1, 12, batch_first=True, bidirectional=True)\n",
    "        self.embedding = nn.Linear(24, self.latent_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.mn = nn.Linear(self.latent_dim, self.latent_dim)\n",
    "        self.sd = nn.Linear(self.latent_dim, self.latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, (_, __) = self.lstm(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.embedding(x)\n",
    "        x = self.relu(x)\n",
    "        mn = self.mn(x)\n",
    "        sd = self.sd(x)\n",
    "        std = torch.exp(sd * 0.5).cuda()\n",
    "        eps = torch.normal(0, 1, size=std.size()).cuda()\n",
    "        out = eps.mul(std).add_(mn).cuda()\n",
    "\n",
    "        return out, mn, sd\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=12):\n",
    "        self.latent_dim = latent_dim\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            latent_dim, 12, batch_first=True, bidirectional=True)\n",
    "        self.tdd = nn.Conv1d(24, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x[:, :, None]\n",
    "        x = x.transpose(1, 2)\n",
    "        x = x.repeat([1, 10, 1])\n",
    "        x, (_, __) = self.lstm(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.tdd(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ulgLsdiBOemp",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "encoder = Encoder().to(device)\n",
    "decoder = Decoder().to(device)\n",
    "model = Autoencoder(encoder, decoder).to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xbO7VYDOlRo",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def Train(\n",
    "    model,\n",
    "    encoder,\n",
    "    decoder,\n",
    "    train_iterator,\n",
    "    optimizer,\n",
    "    epochs,\n",
    "    coef=0,\n",
    "    coef_1=0,\n",
    "    ln_parm=1,\n",
    "    beta_step_size=0,\n",
    "    epoch_per_beta=10,\n",
    "    initial_epochs=10,\n",
    "    device=device,\n",
    "    save=False,\n",
    "):\n",
    "\n",
    "    N_EPOCHS = epochs\n",
    "    best_train_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "\n",
    "        if epoch < initial_epochs:\n",
    "\n",
    "            beta = 0\n",
    "        else:\n",
    "\n",
    "            beta = ((epoch - initial_epochs) //\n",
    "                    epoch_per_beta + 1) * beta_step_size\n",
    "\n",
    "        train_loss = loss_function(\n",
    "            model,\n",
    "            encoder,\n",
    "            decoder,\n",
    "            train_iterator,\n",
    "            optimizer,\n",
    "            coef,\n",
    "            coef_1,\n",
    "            ln_parm,\n",
    "            beta=beta,\n",
    "            mse=False,\n",
    "        )\n",
    "\n",
    "        train_loss /= len(train_iterator)\n",
    "        print(f\"Epoch {epoch}, Train Loss: {train_loss:.4f}\")\n",
    "        print(\".............................\")\n",
    "\n",
    "        if save:\n",
    "            if (\n",
    "                (epoch - initial_epochs) // epoch_per_beta\n",
    "                == (epoch - initial_epochs) / epoch_per_beta\n",
    "            ) and (epoch >= initial_epochs):\n",
    "\n",
    "                best_train_loss = float(\"inf\")\n",
    "\n",
    "            if best_train_loss > train_loss:\n",
    "                best_train_loss = train_loss\n",
    "                patience_counter = 1\n",
    "                checkpoint = {\n",
    "                    \"net\": model.state_dict(),\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                    \"epoch\": epoch,\n",
    "                    \"encoder\": encoder.state_dict(),\n",
    "                    \"decoder\": decoder.state_dict(),\n",
    "                }\n",
    "                if epoch >= 0:\n",
    "                    torch.save(\n",
    "                        checkpoint, f\"./test__Train_Loss:{train_loss:.4f}-{epoch}.pkl\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EegwEd0COuvi",
    "outputId": "38144715-6003-4292-e75f-0ad4875725e0",
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "random_seed(seed=42)\n",
    "\n",
    "Train(\n",
    "    model,\n",
    "    encoder,\n",
    "    decoder,\n",
    "    train_iterator,\n",
    "    optimizer,\n",
    "    500,\n",
    "    beta_step_size=0.05,\n",
    "    epoch_per_beta=100,\n",
    "    initial_epochs=200,\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxunC4NeOyRh",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "encoded_spectra, mn, sd = encoder(\n",
    "    torch.tensor(np.atleast_3d(dog_data), dtype=torch.float32).to(device)\n",
    ")\n",
    "decoded_spectra = decoder(encoded_spectra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dw7pOf7URXGH",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "encoded_spectra = encoded_spectra.to(\"cpu\")\n",
    "encoded_spectra = encoded_spectra.detach().numpy()\n",
    "decoded_spectra = decoded_spectra.to(\"cpu\")\n",
    "decoded_spectra = decoded_spectra.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "66liHx3RRkJ0",
    "outputId": "39595dc2-eca5-4d44-cdd6-f97f35b8bd81",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "embeddings(encoded_spectra, shape_=image.shape[0:2], figsize=(4.5, 3.75))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "kgIgCRKSScS-",
    "outputId": "5fc2842a-c1f5-4938-864a-fa6581a2e3fb",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "latent_generator(decoder, encoded_spectra, image, 5, 10,\n",
    "                 device=device, figsize=(5, 2.5), divider_=False, indx=[1, 3, 4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBt3PEUmTGOs",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- disentanglement with $\\beta$ VAE requires careful control of optimiztion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4YyAVHNSrQR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Autoencoder Tutorial",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "28d6d9e31a694f2aba28d42b1019d9365f56410d563150feaee59905aa4508a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
