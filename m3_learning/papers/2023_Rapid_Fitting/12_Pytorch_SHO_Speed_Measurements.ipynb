{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHO Fitter Speed Measurements Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.signal import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from src.m3_learning.optimizers.AdaHessian import AdaHessian\n",
    "from src.m3_learning.nn.SHO_fitter.SHO import SHO_fit_func_torch\n",
    "from src.m3_learning.be.processing import convert_amp_phase, transform_params, SHO_fit_to_array\n",
    "from src.m3_learning.util.preprocessing import global_scaler\n",
    "from src.m3_learning.nn.benchmarks.inference import computeTime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets path to file\n",
    "path = r\"./\"\n",
    "\n",
    "# Opens the data file\n",
    "h5_f = h5py.File(path + \"data_file.h5\", \"r+\")\n",
    "\n",
    "# number of pixels in the image\n",
    "num_pix = h5_f[\"Measurement_000\"].attrs[\"num_pix\"]\n",
    "\n",
    "num_pix_1d = int(np.sqrt(num_pix))\n",
    "\n",
    "# Frequency Vector in Hz\n",
    "frequency_bin = h5_f[\"Measurement_000\"][\"Channel_000\"][\"Bin_Frequencies\"][:]\n",
    "\n",
    "# extracting spectroscopic values\n",
    "spectroscopic_values = h5_f['Measurement_000']['Channel_000']['Spectroscopic_Values']\n",
    "\n",
    "# number of DC voltage steps\n",
    "voltage_steps = h5_f[\"Measurement_000\"].attrs[\"num_udvs_steps\"]\n",
    "\n",
    "# Resampled frequency vector\n",
    "wvec_freq = resample(frequency_bin, 80)\n",
    "\n",
    "# get raw data (real and imaginary combined)\n",
    "raw_data = h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data\"]\n",
    "raw_data_resampled = resample(np.array(h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data\"]).reshape(-1, 165), 80, axis=1)\n",
    "\n",
    "# conversion of raw data (both resampled and full)\n",
    "amp, phase = convert_amp_phase(raw_data)\n",
    "amp_resample, phase_resample = convert_amp_phase(raw_data_resampled)\n",
    "\n",
    "scaled_data = h5_f[\"Measurement_000\"][\"Channel_000\"]['complex']['scaled_data'][:]\n",
    "real_resample = h5_f[\"Measurement_000\"][\"Channel_000\"]['complex']['real_resample'][:]\n",
    "imag_resample = h5_f[\"Measurement_000\"][\"Channel_000\"]['complex']['imag_resample'][:]\n",
    "\n",
    "# scale the real component of input data\n",
    "scaler_real = global_scaler()\n",
    "scaled_data_real = scaler_real.fit_transform(real_resample).reshape(-1, 80)\n",
    "\n",
    "# scale the imaginary component of input data\n",
    "scaler_imag = global_scaler()\n",
    "scaled_data_imag = scaler_imag.fit_transform(imag_resample).reshape(-1, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list for parameters\n",
    "fit_results_list = SHO_fit_to_array(h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data-SHO_Fit_000\"][\"Fit\"])\n",
    "\n",
    "# flatten parameters list into numpy array\n",
    "fit_results_list = np.array(fit_results_list).reshape(num_pix, voltage_steps, 5)\n",
    "\n",
    "# exclude the R2 parameter\n",
    "params = fit_results_list.reshape(-1, 5)[:, 0:4]\n",
    "\n",
    "# scale the parameters (now takes only 4 parameters, excluding the R2)\n",
    "params_scaler = StandardScaler()\n",
    "scaled_params = params_scaler.fit_transform(fit_results_list.reshape(-1, 5)[:, 0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, params_train, params_test = train_test_split(\n",
    "    scaled_data, scaled_params, test_size=0.7, random_state=42\n",
    ")\n",
    "\n",
    "params_test_unscaled = params_scaler.inverse_transform(params_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed = np.arange(1, 11, 1)\n",
    "optimizers = [torch.optim.Adam, AdaHessian]\n",
    "optimizers_name = [\"ADAM\", \"ADAHESSIAN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, optim in enumerate(optimizers):\n",
    "  with open(f'{optimizers_name[k]}_SHO_speed.txt', 'w') as file:  \n",
    "    for seed in manual_seed:\n",
    "      file.write(f'MANUAL SEED: {seed}\\n')\n",
    "      \n",
    "      for n in range(6, 11):\n",
    "        \n",
    "        class SHO_Model(nn.Module):\n",
    "          def __init__(self):\n",
    "              super().__init__()\n",
    "\n",
    "              # Input block of 1d convolution\n",
    "              self.hidden_x1 = nn.Sequential(\n",
    "                  nn.Conv1d(in_channels=2, out_channels=8, kernel_size=7),\n",
    "                  nn.SELU(),\n",
    "                  nn.Conv1d(in_channels=8, out_channels=6, kernel_size=7),\n",
    "                  nn.SELU(),\n",
    "                  nn.Conv1d(in_channels=6, out_channels=4, kernel_size=5),\n",
    "                  nn.SELU(),\n",
    "              )\n",
    "\n",
    "              # fully connected block\n",
    "              self.hidden_xfc = nn.Sequential(\n",
    "                  nn.Linear(256, 20),\n",
    "                  nn.SELU(),\n",
    "                  nn.Linear(20, 20),\n",
    "                  nn.SELU(),\n",
    "              )\n",
    "\n",
    "              # 2nd block of 1d-conv layers\n",
    "              self.hidden_x2 = nn.Sequential(\n",
    "                  nn.MaxPool1d(kernel_size=2),\n",
    "                  nn.Conv1d(in_channels=2, out_channels=4, kernel_size=5),\n",
    "                  nn.SELU(),\n",
    "                  nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "                  nn.SELU(),\n",
    "                  nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "                  nn.SELU(),\n",
    "                  nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "                  nn.SELU(),\n",
    "                  nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "                  nn.SELU(),\n",
    "                  nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "                  nn.SELU(),\n",
    "                  nn.AvgPool1d(kernel_size=2),\n",
    "                  nn.Conv1d(in_channels=4, out_channels=2, kernel_size=3),\n",
    "                  nn.SELU(),\n",
    "                  nn.AvgPool1d(kernel_size=2),\n",
    "                  nn.Conv1d(in_channels=2, out_channels=2, kernel_size=3),\n",
    "                  nn.SELU(),\n",
    "                  nn.AvgPool1d(kernel_size=2),\n",
    "              )\n",
    "\n",
    "              # Flatten layer\n",
    "              self.flatten_layer = nn.Flatten()\n",
    "              \n",
    "              # Final embedding block - Output 4 values - linear\n",
    "              self.hidden_embedding = nn.Sequential(\n",
    "                  nn.Linear(26, 16),\n",
    "                  nn.SELU(),\n",
    "                  nn.Linear(16, 8),\n",
    "                  nn.SELU(),\n",
    "                  nn.Linear(8, 4),\n",
    "              )\n",
    "\n",
    "          def forward(self, x, n=-1):\n",
    "            x = torch.swapaxes(x, 1, 2) # output shape - samples, (real, imag), frequency\n",
    "            x = self.hidden_x1(x)\n",
    "            xfc = torch.reshape(x, (n, 256)) # batch size, features\n",
    "            xfc = self.hidden_xfc(xfc)\n",
    "            x = torch.reshape(x, (n, 2, 128)) # batch size, (real, imag), timesteps\n",
    "            x = self.hidden_x2(x)\n",
    "            cnn_flat = self.flatten_layer(x)\n",
    "            encoded = torch.cat((cnn_flat, xfc), 1) # merge dense and 1d conv.\n",
    "            embedding = self.hidden_embedding(encoded) # output is 4 parameters\n",
    "\n",
    "            # corrects the scaling of the parameters\n",
    "            unscaled_param = embedding*torch.tensor(params_scaler.var_[0:4]**0.5).cuda() \\\n",
    "                                    + torch.tensor(params_scaler.mean_[0:4]).cuda()\n",
    "\n",
    "            # passes to the pytorch fitting function \n",
    "            fits = SHO_fit_func_torch(unscaled_param, wvec_freq, device='cuda')\n",
    "\n",
    "            # extract and return real and imaginary      \n",
    "            real = torch.real(fits)\n",
    "            real_scaled = (real - torch.tensor(scaler_real.mean).cuda())\\\n",
    "                                              /torch.tensor(scaler_real.std).cuda()\n",
    "            imag = torch.imag(fits)\n",
    "            imag_scaled = (imag - torch.tensor(scaler_imag.mean).cuda())\\\n",
    "                                              /torch.tensor(scaler_imag.std).cuda()\n",
    "            out = torch.stack((real_scaled, imag_scaled), 2)\n",
    "            return out\n",
    "\n",
    "        ##########################################################################################################\n",
    "        # TRAINING\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.cuda.empty_cache()\n",
    "        model = SHO_Model().cuda().double()\n",
    "\n",
    "        loss_func = torch.nn.MSELoss()\n",
    "        batch_size = 2**n\n",
    "        optimizer = optim(model.parameters())\n",
    "        train_dataloader = DataLoader(data_train, batch_size=batch_size)\n",
    "        epochs = 5\n",
    "        \n",
    "        start_time_training = time.time()\n",
    "        for epoch in range(epochs):\n",
    "          start_time = time.time()\n",
    "          train_loss = 0.\n",
    "          total_num = 0\n",
    "\n",
    "          model.train()\n",
    "\n",
    "          for train_batch in train_dataloader:\n",
    "            pred = model(train_batch.double().cuda())\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_func(train_batch.double().cuda(), pred)\n",
    "            loss.backward(create_graph=True)\n",
    "            train_loss += loss.item() * pred.shape[0]\n",
    "            total_num += pred.shape[0]\n",
    "            optimizer.step()\n",
    "\n",
    "          train_loss /= total_num\n",
    "          torch.save(model, f'Trained Models/SHO Fitter/model_{optimizers_name[k]}_{batch_size}.pt')\n",
    "          torch.save(model.state_dict(), f'Trained Models/SHO Fitter/model_{optimizers_name[k]}_{batch_size}.pth')\n",
    "\n",
    "          file.write(\"epoch : {}/{}, recon loss = {:.8f}\\n\".format(epoch + 1, epochs, train_loss))\n",
    "          file.write(\"--- %s seconds ---\\n\" % (time.time() - start_time))\n",
    "\n",
    "        file.write(f\"Training with batch size={batch_size} took {time.time() - start_time_training} seconds\\n\\n\")\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        train_dataloader_valid = DataLoader(scaled_data, batch_size=batch_size)\n",
    "\n",
    "        # Computes the inference time\n",
    "        file.write(f\"Inference time with batch size={batch_size}\\n\")\n",
    "        file.write(computeTime(model, next(iter(train_dataloader_valid)).double(), batch_size=batch_size, write_to_file=True)+'\\n')\n",
    "\n",
    "        ##########################################################################################################\n",
    "        # prediction of reconstructions\n",
    "        batch_size = 5000\n",
    "        train_dataloader = DataLoader(scaled_data, batch_size=batch_size)\n",
    "\n",
    "        num_elements = len(train_dataloader.dataset)\n",
    "        num_batches = len(train_dataloader)\n",
    "        predictions = torch.zeros_like(torch.tensor(scaled_data))\n",
    "\n",
    "        for i, train_batch in enumerate(train_dataloader):\n",
    "          start = i*batch_size\n",
    "          end = start + batch_size\n",
    "\n",
    "          if i == num_batches - 1:\n",
    "            end = num_elements\n",
    "\n",
    "          pred_batch = model(train_batch.double().cuda())\n",
    "          predictions[start:end] = pred_batch.cpu().detach()\n",
    "\n",
    "          del pred_batch\n",
    "          del train_batch\n",
    "          torch.cuda.empty_cache()\n",
    "\n",
    "        file.write('Reconstruction error: ' + str((mean_squared_error(scaled_data[:, :, 0], predictions[:, :, 0]) + mean_squared_error(scaled_data[:, :, 1], predictions[:, :, 1]))/ 2.0) + '\\n')\n",
    "\n",
    "        ##########################################################################################################\n",
    "        # ARCHITECTURE OF PARAMS MODEL\n",
    "        class SHO_Model(nn.Module):\n",
    "          def __init__(self):\n",
    "              super().__init__()\n",
    "\n",
    "              # Input block of 1d convolution\n",
    "              self.hidden_x1 = nn.Sequential(\n",
    "                  nn.Conv1d(in_channels=2, out_channels=8, kernel_size=7),\n",
    "                  nn.SELU(),\n",
    "                  nn.Conv1d(in_channels=8, out_channels=6, kernel_size=7),\n",
    "                  nn.SELU(),\n",
    "                  nn.Conv1d(in_channels=6, out_channels=4, kernel_size=5),\n",
    "                  nn.SELU(),\n",
    "              )\n",
    "\n",
    "              # fully connected block\n",
    "              self.hidden_xfc = nn.Sequential(\n",
    "                  nn.Linear(256, 20),\n",
    "                  nn.SELU(),\n",
    "                  nn.Linear(20, 20),\n",
    "                  nn.SELU(),\n",
    "              )\n",
    "\n",
    "              # 2nd block of 1d-conv layers\n",
    "              self.hidden_x2 = nn.Sequential(\n",
    "                  nn.MaxPool1d(kernel_size=2),\n",
    "                  nn.Conv1d(in_channels=2, out_channels=4, kernel_size=5),\n",
    "                  nn.SELU(),\n",
    "                  nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "                  nn.SELU(),\n",
    "                  nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "                  nn.SELU(),\n",
    "                  nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "                  nn.SELU(),\n",
    "                  nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "                  nn.SELU(),\n",
    "                  nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "                  nn.SELU(),\n",
    "                  nn.AvgPool1d(kernel_size=2),\n",
    "                  nn.Conv1d(in_channels=4, out_channels=2, kernel_size=3),\n",
    "                  nn.SELU(),\n",
    "                  nn.AvgPool1d(kernel_size=2),\n",
    "                  nn.Conv1d(in_channels=2, out_channels=2, kernel_size=3),\n",
    "                  nn.SELU(),\n",
    "                  nn.AvgPool1d(kernel_size=2),\n",
    "              )\n",
    "\n",
    "              # Flatten layer\n",
    "              self.flatten_layer = nn.Flatten()\n",
    "              \n",
    "              # Final embedding block - Output 4 values - linear\n",
    "              self.hidden_embedding = nn.Sequential(\n",
    "                  nn.Linear(26, 16),\n",
    "                  nn.SELU(),\n",
    "                  nn.Linear(16, 8),\n",
    "                  nn.SELU(),\n",
    "                  nn.Linear(8, 4),\n",
    "              )\n",
    "\n",
    "          def forward(self, x, n=-1):\n",
    "            x = torch.swapaxes(x, 1, 2) # output shape - samples, (real, imag), frequency\n",
    "            x = self.hidden_x1(x)\n",
    "            xfc = torch.reshape(x, (n, 256)) # batch size, features\n",
    "            xfc = self.hidden_xfc(xfc)\n",
    "            x = torch.reshape(x, (n, 2, 128)) # batch size, (real, imag), timesteps\n",
    "            x = self.hidden_x2(x)\n",
    "            cnn_flat = self.flatten_layer(x)\n",
    "            encoded = torch.cat((cnn_flat, xfc), 1) # merge dense and 1d conv.\n",
    "            embedding = self.hidden_embedding(encoded) # output is 4 parameters\n",
    "\n",
    "            # corrects the scaling of the parameters\n",
    "            unscaled_param = embedding*torch.tensor(params_scaler.var_[0:4]**0.5).cuda() + torch.tensor(params_scaler.mean_[0:4]).cuda()\n",
    "            return unscaled_param\n",
    "        \n",
    "        ##########################################################################################################\n",
    "        # LOADING PARAMS MODEL\n",
    "        batch_size = 2**n\n",
    "        torch.cuda.empty_cache()\n",
    "        model_parameters = SHO_Model().cuda()\n",
    "        # loads prior trained model\n",
    "        model_parameters = torch.load(f'Trained Models/SHO Fitter/model_{optimizers_name[k]}_{batch_size}.pt')\n",
    "\n",
    "        ##########################################################################################################\n",
    "        # prediction of parameters\n",
    "        batch_size = 5000\n",
    "        train_dataloader = DataLoader(data_test, batch_size=batch_size)\n",
    "\n",
    "        num_elements = len(train_dataloader.dataset)\n",
    "        num_batches = len(train_dataloader)\n",
    "        test_pred_params = torch.zeros_like(torch.tensor(params_test))\n",
    "\n",
    "        for i, train_batch in enumerate(train_dataloader):\n",
    "          start = i*batch_size\n",
    "          end = start + batch_size\n",
    "\n",
    "          if i == num_batches - 1:\n",
    "            end = num_elements\n",
    "\n",
    "          pred_batch = model_parameters(train_batch.double().cuda())\n",
    "          test_pred_params[start:end] = pred_batch.cpu().detach()\n",
    "\n",
    "          del pred_batch\n",
    "          del train_batch\n",
    "          torch.cuda.empty_cache()\n",
    "\n",
    "        test_pred_params = test_pred_params.view(-1, 4)\n",
    "        test_pred_params = test_pred_params.cpu().detach().numpy()\n",
    "\n",
    "        # making numpy array copies of parameters\n",
    "        test_params_copy = np.copy(params_test_unscaled)\n",
    "        test_pred_params_copy = np.copy(test_pred_params)\n",
    "\n",
    "        params_transformed, pred_params_transformed = transform_params(test_params_copy, test_pred_params_copy)\n",
    "\n",
    "        ###########################################################################################################\n",
    "        # prediction of parameters\n",
    "        batch_size = 5000\n",
    "        train_dataloader = DataLoader(scaled_data, batch_size=batch_size)\n",
    "\n",
    "        num_elements = len(train_dataloader.dataset)\n",
    "        num_batches = len(train_dataloader)\n",
    "        all_pred_params = torch.zeros_like(torch.tensor(params))\n",
    "\n",
    "        for i, train_batch in enumerate(train_dataloader):\n",
    "          start = i*batch_size\n",
    "          end = start + batch_size\n",
    "\n",
    "          if i == num_batches - 1:\n",
    "            end = num_elements\n",
    "\n",
    "          pred_batch = model_parameters(train_batch.double().cuda())\n",
    "          all_pred_params[start:end] = pred_batch.cpu().detach()\n",
    "\n",
    "          del pred_batch\n",
    "          del train_batch\n",
    "          torch.cuda.empty_cache()\n",
    "\n",
    "        all_pred_params = all_pred_params.cpu().detach().numpy()\n",
    "\n",
    "        params_copy = np.copy(params)\n",
    "        all_pred_params_copy = np.copy(all_pred_params)\n",
    "\n",
    "        all_params_transformed, all_pred_params_transformed = transform_params(params_copy, all_pred_params_copy)\n",
    "\n",
    "        all_pred_params_scaled = params_scaler.transform(all_pred_params_transformed)\n",
    "        all_params_scaled = params_scaler.transform(all_params_transformed)\n",
    "\n",
    "        file.write('\\nResults')\n",
    "        file.write('Total MSE: ' + str(mean_squared_error(all_params_scaled, all_pred_params_scaled)) + '\\n')\n",
    "        file.write('MSE of Amplitude: ' + str(mean_squared_error(all_params_scaled[:, 0], all_pred_params_scaled[:, 0])) + '\\n')\n",
    "        file.write('MSE of Resonance: ' + str(mean_squared_error(all_params_scaled[:, 1], all_pred_params_scaled[:, 1])) + '\\n')\n",
    "        file.write('MSE of Quality-Factor: ' + str(mean_squared_error(all_params_scaled[:, 2], all_pred_params_scaled[:, 2])) + '\\n')\n",
    "        file.write('MSE of Phase: ' + str(mean_squared_error(all_params_scaled[:, 3], all_pred_params_scaled[:, 3])) + '\\n')\n",
    "        file.write('------------------------------\\n\\n')\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapid_fitting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c58f42fd11d8ae4df132d3c425059695e86ccc63a852aa66615442730ca8b1fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
