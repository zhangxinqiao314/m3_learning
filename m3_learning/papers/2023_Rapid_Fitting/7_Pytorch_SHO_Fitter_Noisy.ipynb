{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHO Fitter on the noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "sys.path.append('/home/ferroelectric/m3_learning/m3_learning/src')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gdown'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mshutil\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgc\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgdown\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gdown'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import gc\n",
    "import gdown\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.signal import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from src.m3_learning.optimizers.AdaHessian import AdaHessian\n",
    "from src.m3_learning.nn.SHO_fitter.SHO import SHO_fit_func_torch\n",
    "from src.m3_learning.be.processing import convert_amp_phase, SHO_Fitter, SHO_fit_to_array\n",
    "from src.m3_learning.nn.random import random_seed\n",
    "from src.m3_learning.util.preprocessing import global_scaler\n",
    "from src.m3_learning.viz.layout import layout_fig\n",
    "\n",
    "from src.m3_learning.be.util import print_be_tree\n",
    "\n",
    "from src.m3_learning.viz.printing import printer\n",
    "from src.m3_learning.viz.layout import combine_lines, labelfigs\n",
    "\n",
    "\n",
    "printing = printer(basepath='./figures/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdown.download(\n",
    "    \"https://drive.google.com/uc?export=download&id=1Q2Qo_1VGlCsVOTjQpZlE5tjoIV1etVe2\",\n",
    "    path + \"data_file_google.h5\",\n",
    "    quiet=False,\n",
    "    resume=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets path to file\n",
    "path = r\"./\"\n",
    "\n",
    "# Opens the data file\n",
    "h5_f = h5py.File(path + \"data_file.h5\", \"r+\")\n",
    "\n",
    "# number of pixels in the image\n",
    "num_pix = h5_f[\"Measurement_000\"].attrs[\"num_pix\"]\n",
    "\n",
    "num_pix_1d = int(np.sqrt(num_pix))\n",
    "\n",
    "# Frequency Vector in Hz\n",
    "frequency_bin = h5_f[\"Measurement_000\"][\"Channel_000\"][\"Bin_Frequencies\"][:]\n",
    "\n",
    "# extracting spectroscopic values\n",
    "spectroscopic_values = h5_f['Measurement_000']['Channel_000']['Spectroscopic_Values']\n",
    "\n",
    "# number of DC voltage steps\n",
    "voltage_steps = h5_f[\"Measurement_000\"].attrs[\"num_udvs_steps\"]\n",
    "\n",
    "# Resampled frequency vector\n",
    "wvec_freq = resample(frequency_bin, 80)\n",
    "\n",
    "# get raw data (real and imaginary combined)\n",
    "raw_data = h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data\"]\n",
    "raw_data_resampled = resample(np.array(h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data\"]).reshape(-1, 165), 80, axis=1)\n",
    "\n",
    "# conversion of raw data (both resampled and full)\n",
    "amp, phase = convert_amp_phase(raw_data)\n",
    "amp_resample, phase_resample = convert_amp_phase(raw_data_resampled)\n",
    "\n",
    "scaled_data = h5_f[\"Measurement_000\"][\"Channel_000\"]['complex']['scaled_data'][:]\n",
    "real_resample = h5_f[\"Measurement_000\"][\"Channel_000\"]['complex']['real_resample'][:]\n",
    "imag_resample = h5_f[\"Measurement_000\"][\"Channel_000\"]['complex']['imag_resample'][:]\n",
    "\n",
    "# scale the real component of input data\n",
    "scaler_real = global_scaler()\n",
    "scaled_data_real = scaler_real.fit_transform(real_resample).reshape(-1, 80)\n",
    "\n",
    "# scale the imaginary component of input data\n",
    "scaler_imag = global_scaler()\n",
    "scaled_data_imag = scaler_imag.fit_transform(imag_resample).reshape(-1, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list for parameters\n",
    "fit_results_list = SHO_fit_to_array(h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data-SHO_Fit_000\"][\"Fit\"])\n",
    "\n",
    "# flatten parameters list into numpy array\n",
    "fit_results_list = np.array(fit_results_list).reshape(num_pix, voltage_steps, 5)\n",
    "\n",
    "# exclude the R2 parameter\n",
    "params = fit_results_list.reshape(-1, 5)[:, 0:4]\n",
    "\n",
    "# scale the parameters (now takes only 4 parameters, excluding the R2)\n",
    "params_scaler = StandardScaler()\n",
    "scaled_params = params_scaler.fit_transform(fit_results_list.reshape(-1, 5)[:, 0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_noise_real = -1.0 * 0.0026878386 # 2.6e-3\n",
    "highest_noise_real = 1.0 * 0.0026878386\n",
    "lowest_noise_imag = -1.0 * 0.0027575183\n",
    "highest_noise_imag = 1.0 * 0.0027575183\n",
    "\n",
    "noise_real = np.random.uniform(lowest_noise_real, highest_noise_real, (3600, 63360))\n",
    "noise_imag = np.random.uniform(lowest_noise_imag, highest_noise_imag, (3600, 63360))\n",
    "noise = noise_real+noise_imag*1.0j\n",
    "\n",
    "noise_levels = ['2.0', '4.0', '7.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all computations were pre-computed on A100 40GB NHI GPU\n",
    "# set to False if you want to recompute\n",
    "use_pre_computed_vars = False\n",
    "use_pre_trained_models = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_be_tree('./data_file_noise_7.0.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copies initial dataset for the later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_pre_computed_vars:\n",
    "  # close the current file to perform a copy\n",
    "  h5_f.close()\n",
    "  for nl in noise_levels:\n",
    "    shutil.copy('data_file_raw.h5', f'data_file_noise_{nl}.h5')\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_level in noise_levels:\n",
    "  \n",
    "  with h5py.File(f'data_file_noise_{noise_level}.h5', 'r+') as h5_f_noise:\n",
    "    data_pointer = h5_f_noise['Measurement_000']['Channel_000']['Raw_Data']\n",
    "    raw_data_noise = np.array(h5_f_noise['Measurement_000']['Channel_000']['Raw_Data'])\n",
    "    raw_data_noise = raw_data_noise + noise * float(noise_level) \n",
    "    data_pointer[...] = raw_data_noise\n",
    "    del h5_f_noise['Measurement_000']['Channel_000']['Raw_Data-SHO_Fit_000']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Builds the PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHO_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input block of 1d convolution\n",
    "        self.hidden_x1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=2, out_channels=8, kernel_size=7),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=8, out_channels=6, kernel_size=7),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=6, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "        )\n",
    "\n",
    "        # fully connected block\n",
    "        self.hidden_xfc = nn.Sequential(\n",
    "            nn.Linear(256, 20),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.SELU(),\n",
    "        )\n",
    "\n",
    "        # 2nd block of 1d-conv layers\n",
    "        self.hidden_x2 = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=2, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=4, out_channels=2, kernel_size=3),\n",
    "            nn.SELU(),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=2, out_channels=2, kernel_size=3),\n",
    "            nn.SELU(),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        # Flatten layer\n",
    "        self.flatten_layer = nn.Flatten()\n",
    "\n",
    "        # Final embedding block - Output 4 values - linear\n",
    "        self.hidden_embedding = nn.Sequential(\n",
    "            nn.Linear(26, 16),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(8, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, n=-1):\n",
    "        x = torch.swapaxes(x, 1, 2)  # output shape - samples, (real, imag), frequency\n",
    "        x = self.hidden_x1(x)\n",
    "        xfc = torch.reshape(x, (n, 256))  # batch size, features\n",
    "        xfc = self.hidden_xfc(xfc)\n",
    "        x = torch.reshape(x, (n, 2, 128))  # batch size, (real, imag), timesteps\n",
    "        x = self.hidden_x2(x)\n",
    "        cnn_flat = self.flatten_layer(x)\n",
    "        encoded = torch.cat((cnn_flat, xfc), 1)  # merge dense and 1d conv.\n",
    "        embedding = self.hidden_embedding(encoded)  # output is 4 parameters\n",
    "\n",
    "        # corrects the scaling of the parameters\n",
    "        unscaled_param = (\n",
    "            embedding * torch.tensor(params_scaler.var_[0:4] ** 0.5).cuda()\n",
    "            + torch.tensor(params_scaler.mean_[0:4]).cuda()\n",
    "        )\n",
    "\n",
    "        # passes to the pytorch fitting function\n",
    "        fits = SHO_fit_func_torch(unscaled_param, wvec_freq, device=\"cuda\")\n",
    "\n",
    "        # extract and return real and imaginary\n",
    "        real = torch.real(fits)\n",
    "        real_scaled = (real - torch.tensor(scaler_real.mean).cuda()) / torch.tensor(\n",
    "            scaler_real.std\n",
    "        ).cuda()\n",
    "        imag = torch.imag(fits)\n",
    "        imag_scaled = (imag - torch.tensor(scaler_imag.mean).cuda()) / torch.tensor(\n",
    "            scaler_imag.std\n",
    "        ).cuda()\n",
    "        out = torch.stack((real_scaled, imag_scaled), 2)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trains NN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, params_train, params_test = train_test_split(\n",
    "    scaled_data, scaled_params, test_size=0.7, random_state=42\n",
    ")\n",
    "\n",
    "params_test_unscaled = params_scaler.inverse_transform(params_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_pre_trained_models:\n",
    "  max_num_of_updates = scaled_data.shape[0] // 16 * 10\n",
    "  output_tensor_dict = {}\n",
    "  seed = 0\n",
    "  noise_reshaped = resample(noise.reshape(-1, 165), 80, axis=1)\n",
    "  noise_2d = np.stack((np.real(noise_reshaped), np.imag(noise_reshaped)), axis=2)\n",
    "  noise_train, noise_test = train_test_split(noise_2d, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_pre_trained_models:\n",
    "  for noise_factor in noise_levels:\n",
    "      noise_factor = float(noise_factor)\n",
    "      random_seed(seed=42)\n",
    "      torch.cuda.empty_cache()\n",
    "      model = SHO_Model().cuda()\n",
    "\n",
    "      loss_func = torch.nn.MSELoss()\n",
    "      batch_size = 128\n",
    "      data_noise = scaled_data + noise_2d * noise_factor\n",
    "      data_train_noise = data_train + noise_train * noise_factor\n",
    "      data_test_noise = data_test + noise_test * noise_factor\n",
    "\n",
    "      optimizer = torch.optim.Adam(model.parameters())\n",
    "      train_dataloader = DataLoader(data_train_noise, batch_size=batch_size)\n",
    "      epochs = max_num_of_updates * batch_size // scaled_data.shape[0] // 16\n",
    "      print(f\"Training with batch size = {batch_size}, noise factor = {noise_factor}\")\n",
    "      start_time_training = time.time()\n",
    "      for epoch in range(epochs):\n",
    "          start_time = time.time()\n",
    "          train_loss = 0.\n",
    "          total_num = 0\n",
    "\n",
    "          model.train()\n",
    "\n",
    "          for train_batch in train_dataloader:\n",
    "              pred = model(train_batch.double().cuda())\n",
    "              optimizer.zero_grad()\n",
    "              loss = loss_func(train_batch.double().cuda(), pred)\n",
    "              loss.backward(create_graph=True)\n",
    "              train_loss += loss.item() * pred.shape[0]\n",
    "              total_num += pred.shape[0]\n",
    "              optimizer.step()\n",
    "\n",
    "          train_loss /= total_num\n",
    "          torch.save(model.state_dict(), f'./Trained Models/SHO Fitter/model_noise_{noise_factor}_bs128.pt')\n",
    "\n",
    "          print(\"epoch : {}/{}, recon loss = {:.8f}\".format(epoch + 1, epochs, train_loss))\n",
    "          print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "      print(f\"Training with batch size={batch_size} took {time.time() - start_time_training} seconds\\n\")\n",
    "\n",
    "      del train_dataloader\n",
    "      del data_noise\n",
    "      del data_train_noise\n",
    "      del data_test_noise\n",
    "      del model\n",
    "      gc.collect()\n",
    "      torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computes fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noise_level in noise_levels:\n",
    "    SHO_Fitter(f'data_file_noise_{noise_level}.h5', force=True)\n",
    "    print(f'Computation for noise level={noise_level} is done!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uses Pre-computed Noisy SHO Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: download from Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pre_computed_vars:\n",
    "  !unzip noisy_sho_fits.zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapid_fitting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c58f42fd11d8ae4df132d3c425059695e86ccc63a852aa66615442730ca8b1fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
